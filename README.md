<div align="center">
  <img src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54" alt="Python">
  <img src="https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white" alt="Apache Airflow">
  <img src="https://img.shields.io/badge/docker-%230db7ed.svg?style=for-the-badge&logo=docker&logoColor=white" alt="Docker">
  <img src="https://img.shields.io/badge/postgres-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white" alt="Postgres">
  <img src="https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas">
</div>

# ğŸ¦ Airflow Credit Data Pipeline

Pipeline de Engenharia de Dados **ELT (Extract, Load, Transform)** desenvolvido para automatizar a coleta, processamento e armazenamento de indicadores financeiros oficiais do Banco Central do Brasil.

Este projeto orquestra o ciclo de vida de dados de crÃ©dito utilizando **Apache Airflow** em ambiente containerizado (**Docker**), garantindo reprodutibilidade, escalabilidade e monitoramento.

---

## ğŸ“‹ Sobre o Projeto

O objetivo deste projeto Ã© criar uma base analÃ­tica histÃ³rica para estudos de **Risco de CrÃ©dito**, cruzando dois indicadores econÃ´micos fundamentais disponibilizados pelo Sistema Gerenciador de SÃ©ries Temporais (SGS) do Banco Central:

1.  **Taxa de InadimplÃªncia (PF):** O percentual da carteira de crÃ©dito com atraso superior a 90 dias.
2.  **Taxa MÃ©dia de Juros (PF):** O custo mÃ©dio do crÃ©dito para famÃ­lias.

**Business Value:**
O pipeline permite responder a perguntas estratÃ©gicas, como: *"Existe correlaÃ§Ã£o direta entre o aumento da taxa de juros e a inadimplÃªncia nos meses subsequentes?"*, fornecendo dados limpos e consolidados para times de Analytics e Data Science.

---

## ğŸ›  Tech Stack

* **OrquestraÃ§Ã£o:** Apache Airflow 2.x
* **Infraestrutura as Code:** Docker & Docker Compose
* **Data Warehouse:** PostgreSQL
* **Linguagem de Processamento:** Python (Pandas)
* **Fonte de Dados:** API de Dados Abertos do Banco Central (SGS)

---

## âš™ï¸ Arquitetura da SoluÃ§Ã£o

O fluxo foi desenhado para ser resiliente a falhas e executado mensalmente:

```mermaid
graph LR
    subgraph Source ["ğŸ›ï¸ Banco Central (API)"]
        direction TB
        A[SÃ©rie 21082: InadimplÃªncia]
        B[SÃ©rie 20742: Taxa de Juros]
    end

    subgraph Orchestrator ["ğŸŒ¬ï¸ Apache Airflow (Docker)"]
        direction TB
        C(Task: Extract Data)
        D(Task: Transform & Merge)
        E(Task: Load to Postgres)
        
        C --> D --> E
    end

    subgraph DW ["ğŸ—„ï¸ Data Warehouse"]
        F[(PostgreSQL)]
    end

    A --> C
    B --> C
    E --> F
```

## O Processo de TransformaÃ§Ã£o

1.  **ExtraÃ§Ã£o:** ConexÃ£o com a API do BCB e download dos arquivos CSV brutos.

2.  **TransformaÃ§Ã£o:**

    * NormalizaÃ§Ã£o de separadores (PadrÃ£o BR para US).
    * ConversÃ£o de tipos (String -> Float/Date).
    * **Join:** Cruzamento das duas sÃ©ries temporais pela data de referÃªncia.

3.  **Carga:** PersistÃªncia dos dados tratados na tabela indicadores_credito_bcb no Postgres.

---

## ğŸš€ Como Executar
Este projeto utiliza Docker para subir todo o ambiente (Airflow + Banco de Dados) com um Ãºnico comando, abstraindo instalaÃ§Ãµes complexas.

**PrÃ©-requisitos**

  * Docker Desktop instalado.

**Passo a Passo**

1.   **Clone o repositÃ³rio:**

```Bash

git clone https://github.com/SEU-USUARIO/airflow-credit-data-pipeline.git
cd airflow-credit-data-pipeline
````
2.  **Suba a infraestrutura:**

```Bash

docker-compose up -d
Aguarde alguns minutos atÃ© que todos os containers estejam saudÃ¡veis.
```

3.  **Acesse o Airflow:**

    * Abra o navegador em: http://localhost:8080

    * UsuÃ¡rio: admin

    * Senha: admin

4.  **Configure a ConexÃ£o com o Banco:** No menu superior do Airflow, vÃ¡ em Admin -> Connections, clique no (+) e preencha:

    * **Conn Id:** postgres_default

    * **Conn Type:** Postgres

    * **Host:** postgres

    * **Schema:** airflow

    * **Login:** airflow

    * **Password:** airflow

    * **Port:** 5432

5.  **Execute o Pipeline:** Ative a DAG bcb_credit_indicators_pipeline (botÃ£o ON/OFF) e clique no botÃ£o Play (Trigger DAG).

## ğŸ“Š Estrutura do Projeto

````Plaintext

airflow-credit-data-pipeline/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ credito_elt.py      # CÃ³digo Python da DAG (LÃ³gica do Pipeline)
â”œâ”€â”€ data/                   # Ãrea de stage para arquivos (mapeado no Docker)
â”œâ”€â”€ logs/                   # Logs de execuÃ§Ã£o
â”œâ”€â”€ docker-compose.yaml     # DefiniÃ§Ã£o da Infraestrutura (Airflow + Postgres)
â””â”€â”€ README.md               # DocumentaÃ§Ã£o
````

## ğŸ“ˆ Resultado Final

ApÃ³s a execuÃ§Ã£o com sucesso (caixinhas verdes), os dados estarÃ£o disponÃ­veis no banco de dados PostgreSQL interno, prontos para serem conectados a ferramentas de BI (PowerBI/Tableau) ou consumidos por modelos de Machine Learning.
